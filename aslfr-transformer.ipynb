{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nimport json\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:08:23.776837Z","iopub.execute_input":"2023-05-31T08:08:23.777344Z","iopub.status.idle":"2023-05-31T08:08:33.707423Z","shell.execute_reply.started":"2023-05-31T08:08:23.777299Z","shell.execute_reply":"2023-05-31T08:08:33.706141Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    char_to_num = json.load(f)\n\nnum_to_char = {j:i for i,j in char_to_num.items()}\n\ninpdir = \"/kaggle/input/asl-fingerspelling\"\ndf = pd.read_csv(f'{inpdir}/train.csv')\n\nLIP = [\n    61, 185, 40, 39, 37, 267, 269, 270, 409,\n    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n]\n\nFACE = [f'x_face_{i}' for i in LIP] + [f'y_face_{i}' for i in LIP] + [f'z_face_{i}' for i in LIP]\nLHAND = [f'x_left_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)]\nRHAND = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\nPOSE = [f'x_pose_{i}' for i in range(33)] + [f'y_pose_{i}' for i in range(33)] + [f'z_pose_{i}' for i in range(33)]\n\nX = [f'x_face_{i}' for i in LIP] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_right_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in range(33)]\nY = [f'y_face_{i}' for i in LIP] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in range(33)]\nZ = [f'z_face_{i}' for i in LIP] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in range(33)]\n\n#SEL_COLS = FACE + LHAND + RHAND + POSE\nSEL_COLS = X + Y + Z\nFRAME_LEN = 128","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:08:36.646110Z","iopub.execute_input":"2023-05-31T08:08:36.646918Z","iopub.status.idle":"2023-05-31T08:08:36.854879Z","shell.execute_reply.started":"2023-05-31T08:08:36.646879Z","shell.execute_reply":"2023-05-31T08:08:36.853772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ntable = tf.lookup.StaticHashTable(\n    initializer=tf.lookup.KeyValueTensorInitializer(\n        keys=list(char_to_num.keys()),\n        values=list(char_to_num.values()),\n    ),\n    default_value=tf.constant(-1),\n    name=\"class_weight\"\n)\n\ndef decode_fn(record_bytes):\n    schema = {COL: tf.io.FixedLenFeature([FRAME_LEN], dtype=tf.float32) for COL in SEL_COLS}\n    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n    features = tf.io.parse_single_example(record_bytes, schema)\n    phrase = features[\"phrase\"]\n    landmarks = tf.convert_to_tensor([features[COL] for COL in SEL_COLS])\n    landmarks = tf.transpose(landmarks)\n    mask = tf.math.less(landmarks, -2)\n#     nan_tensor = tf.fill(tf.shape(landmarks), tf.constant(np.nan, dtype=tf.float32))\n    nan_tensor = tf.fill(tf.shape(landmarks), tf.constant(0, dtype=tf.float32))\n    landmarks = tf.where(mask, nan_tensor, landmarks)\n    \n    phrase = '#' + phrase + '$'\n    phrase = tf.strings.bytes_split(phrase)\n    phrase = table.lookup(phrase)\n    phrase = tf.pad(phrase, paddings=[[0, 64 - tf.shape(phrase)[0]]])\n    \n    return landmarks, phrase\n\ninpdir = \"/kaggle/input/aslfr-preprocess-dataset\"\ntffiles = df.file_id.map(lambda x: f'{inpdir}/tfds/{x}.tfrecord').unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:08:42.608843Z","iopub.execute_input":"2023-05-31T08:08:42.609227Z","iopub.status.idle":"2023-05-31T08:08:42.791312Z","shell.execute_reply.started":"2023-05-31T08:08:42.609200Z","shell.execute_reply":"2023-05-31T08:08:42.790193Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nval_len = int(0.2 * len(tffiles))\ntrain_dataset = tf.data.TFRecordDataset(tffiles[val_len:]).map(decode_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_dataset = tf.data.TFRecordDataset(tffiles[:val_len]).map(decode_fn).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:08:56.564387Z","iopub.execute_input":"2023-05-31T08:08:56.564793Z","iopub.status.idle":"2023-05-31T08:08:57.420813Z","shell.execute_reply.started":"2023-05-31T08:08:56.564764Z","shell.execute_reply":"2023-05-31T08:08:57.419773Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class TokenEmbedding(layers.Layer):\n    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n        super().__init__()\n        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        x = self.emb(x)\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        return x + positions\n\n\nclass LandmarkEmbedding(layers.Layer):\n    def __init__(self, num_hid=64, maxlen=100):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n        self.conv2 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n        self.conv3 = tf.keras.layers.Conv1D(\n            num_hid, 11, padding=\"same\", activation=\"relu\"\n        )\n#         self.lstm1 = tf.keras.layers.LSTM(num_hid, return_sequences=True, activation=\"relu\")\n#         self.lstm2 = tf.keras.layers.LSTM(num_hid, return_sequences=True, activation=\"relu\")\n#         self.lstm3 = tf.keras.layers.LSTM(num_hid, return_sequences=True, activation=\"relu\")\n#         self.dense1 = tf.keras.layers.Dense(num_hid, activation=\"relu\")\n#         self.dense2 = tf.keras.layers.Dense(num_hid, activation=\"relu\")\n#         self.dense3 = tf.keras.layers.Dense(num_hid, activation=\"relu\")\n\n    def call(self, x):\n        #x = x[..., tf.newaxis]\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n#         x = self.dense1(x)\n#         x = self.dense2(x)\n#         x = self.dense3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:08:59.959489Z","iopub.execute_input":"2023-05-31T08:08:59.959910Z","iopub.status.idle":"2023-05-31T08:08:59.972442Z","shell.execute_reply.started":"2023-05-31T08:08:59.959880Z","shell.execute_reply":"2023-05-31T08:08:59.971075Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:02.907049Z","iopub.execute_input":"2023-05-31T08:09:02.907510Z","iopub.status.idle":"2023-05-31T08:09:02.917979Z","shell.execute_reply.started":"2023-05-31T08:09:02.907477Z","shell.execute_reply":"2023-05-31T08:09:02.916642Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n        super().__init__()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.self_att = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.self_dropout = layers.Dropout(0.5)\n        self.enc_dropout = layers.Dropout(0.1)\n        self.ffn_dropout = layers.Dropout(0.1)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n\n    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n        \"\"\"Masks the upper half of the dot product matrix in self attention.\n\n        This prevents flow of information from future tokens to current token.\n        1's in the lower triangle, counting from the lower right corner.\n        \"\"\"\n        i = tf.range(n_dest)[:, None]\n        j = tf.range(n_src)\n        m = i >= j - n_src + n_dest\n        mask = tf.cast(m, dtype)\n        mask = tf.reshape(mask, [1, n_dest, n_src])\n        mult = tf.concat(\n            #[tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n            [batch_size[..., tf.newaxis], tf.constant([1, 1], dtype=tf.int32)], 0\n        )\n        return tf.tile(mask, mult)\n\n    def call(self, enc_out, target):\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n        target_att = self.self_att(target, target, attention_mask=causal_mask)\n        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n        enc_out = self.enc_att(target_norm, enc_out)\n        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n        ffn_out = self.ffn(enc_out_norm)\n        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n        return ffn_out_norm","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:06.063610Z","iopub.execute_input":"2023-05-31T08:09:06.064446Z","iopub.status.idle":"2023-05-31T08:09:06.080297Z","shell.execute_reply.started":"2023-05-31T08:09:06.064404Z","shell.execute_reply":"2023-05-31T08:09:06.079156Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Transformer(keras.Model):\n    def __init__(\n        self,\n        num_hid=64,\n        num_head=2,\n        num_feed_forward=128,\n        source_maxlen=100,\n        target_maxlen=100,\n        num_layers_enc=4,\n        num_layers_dec=1,\n        num_classes=10,\n    ):\n        super().__init__()\n        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n        self.num_layers_enc = num_layers_enc\n        self.num_layers_dec = num_layers_dec\n        self.target_maxlen = target_maxlen\n        self.num_classes = num_classes\n\n        self.enc_input = LandmarkEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n        self.dec_input = TokenEmbedding(\n            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n        )\n\n        self.encoder = keras.Sequential(\n            [self.enc_input]\n            + [\n                TransformerEncoder(num_hid, num_head, num_feed_forward)\n                for _ in range(num_layers_enc)\n            ]\n        )\n\n        for i in range(num_layers_dec):\n            setattr(\n                self,\n                f\"dec_layer_{i}\",\n                TransformerDecoder(num_hid, num_head, num_feed_forward),\n            )\n\n        self.classifier = layers.Dense(num_classes)\n\n    def decode(self, enc_out, target):\n        y = self.dec_input(target)\n        for i in range(self.num_layers_dec):\n            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n        return y\n\n    def call(self, inputs):\n        source = inputs[0]\n        target = inputs[1]\n        x = self.encoder(source)\n        y = self.decode(x, target)\n        return self.classifier(y)\n\n    @property\n    def metrics(self):\n        return [self.loss_metric]\n\n    def train_step(self, batch):\n        \"\"\"Processes one batch inside model.fit().\"\"\"\n        source = batch[0]\n        target = batch[1]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        with tf.GradientTape() as tape:\n            preds = self([source, dec_input])\n            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def test_step(self, batch):\n        source = batch[0]\n        target = batch[1]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        preds = self([source, dec_input])\n        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def generate(self, source, target_start_token_idx):\n        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n        bs = tf.shape(source)[0]\n        enc = self.encoder(source)\n        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n        dec_logits = []\n        for i in range(self.target_maxlen - 1):\n            dec_out = self.decode(enc, dec_input)\n            logits = self.classifier(dec_out)\n            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n            #last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n            last_logit = logits[:, -1][..., tf.newaxis]\n            dec_logits.append(last_logit)\n            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n        return dec_input","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:07.846430Z","iopub.execute_input":"2023-05-31T08:09:07.846962Z","iopub.status.idle":"2023-05-31T08:09:07.875327Z","shell.execute_reply.started":"2023-05-31T08:09:07.846919Z","shell.execute_reply":"2023-05-31T08:09:07.874136Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class DisplayOutputs(keras.callbacks.Callback):\n    def __init__(\n        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n    ):\n        \"\"\"Displays a batch of outputs after every epoch\n\n        Args:\n            batch: A test batch containing the keys \"source\" and \"target\"\n            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n            target_start_token_idx: A start token index in the target vocabulary\n            target_end_token_idx: An end token index in the target vocabulary\n        \"\"\"\n        self.batch = batch\n        self.target_start_token_idx = target_start_token_idx\n        self.target_end_token_idx = target_end_token_idx\n        self.idx_to_char = idx_to_token\n\n    def on_epoch_end(self, epoch, logs=None):\n#         if epoch % 5 != 0:\n#             return\n        source = self.batch[0]\n        target = self.batch[1].numpy()\n        bs = tf.shape(source)[0]\n        preds = self.model.generate(source, self.target_start_token_idx)\n        preds = preds.numpy()\n        for i in range(bs):\n            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n            prediction = \"\"\n            for idx in preds[i, :]:\n                prediction += self.idx_to_char[idx]\n                if idx == self.target_end_token_idx:\n                    break\n            print(f\"target:     {target_text.replace('-','')}\")\n            print(f\"prediction: {prediction}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:10.547433Z","iopub.execute_input":"2023-05-31T08:09:10.547856Z","iopub.status.idle":"2023-05-31T08:09:10.559017Z","shell.execute_reply.started":"2023-05-31T08:09:10.547826Z","shell.execute_reply":"2023-05-31T08:09:10.557754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(val_dataset))\n\nidx_to_char = list(char_to_num.keys())\ndisplay_cb = DisplayOutputs(\n    batch, num_to_char, target_start_token_idx=2, target_end_token_idx=3\n)  # set the arguments as per vocabulary index for '<' and '>'\n\nmodel = Transformer(\n    num_hid=200,\n    num_head=2,\n    num_feed_forward=400,\n    target_maxlen=64,\n    num_layers_enc=4,\n    num_layers_dec=1,\n    num_classes=59,\n)\n\nloss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1,)\noptimizer = keras.optimizers.Adam(0.0001)\nmodel.compile(optimizer=optimizer, loss=loss_fn)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:13.015358Z","iopub.execute_input":"2023-05-31T08:09:13.015769Z","iopub.status.idle":"2023-05-31T08:09:13.589070Z","shell.execute_reply.started":"2023-05-31T08:09:13.015734Z","shell.execute_reply":"2023-05-31T08:09:13.588004Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, validation_data=val_dataset, callbacks=[display_cb], epochs=50)\n# history = model.fit(train_dataset.take(1), validation_data=val_dataset.take(1), callbacks=[display_cb], epochs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PreprocessLayer(tf.keras.layers.Layer):\n    def __init__(self):\n        super(PreprocessLayer, self).__init__()\n        \n    def __call__(self, x):\n        #x = tf.expand_dims(x, 0)\n        x = x[None]\n        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n        x = tf.image.resize(x, (tf.shape(x)[0], FRAME_LEN))\n        x = x[0]\n        return x\n    \nclass TFLiteModel(tf.Module):\n    def __init__(self, model):\n        super(TFLiteModel, self).__init__()\n\n        # Load the feature generation and main models\n        self.preprocess_layer = PreprocessLayer()\n        self.model = model\n    \n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n    def __call__(self, inputs, training=False):\n        # Preprocess Data\n        x = self.preprocess_layer(inputs)\n        #x = tf.expand_dims(x, 0)\n        x = x[None]\n        x = self.model.generate(x, 2)\n        x = x[0]\n        idx = tf.argmax(tf.cast(tf.equal(x, 3), tf.int32))\n        idx = tf.where(tf.math.less(idx, 1), tf.constant(3, dtype=tf.int64), idx)\n        x = x[1:idx]\n        x = tf.one_hot(x, 59)\n        return {'outputs': x}\n    \npre = PreprocessLayer()\nprint(pre(batch[0][0]).shape)\ntflitemodel_base = TFLiteModel(model)\nprint(batch[0][0].shape)\ntflitemodel_base(batch[0][0])[\"outputs\"].shape","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:10:57.728108Z","iopub.execute_input":"2023-05-31T08:10:57.728528Z","iopub.status.idle":"2023-05-31T08:11:14.374276Z","shell.execute_reply.started":"2023-05-31T08:10:57.728496Z","shell.execute_reply":"2023-05-31T08:11:14.373028Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(128, 342)\n(128, 342)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TensorShape([21, 59])"},"metadata":{}}]},{"cell_type":"code","source":"model.save_weights(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:12:49.471505Z","iopub.execute_input":"2023-05-31T08:12:49.471921Z","iopub.status.idle":"2023-05-31T08:12:49.605332Z","shell.execute_reply.started":"2023-05-31T08:12:49.471891Z","shell.execute_reply":"2023-05-31T08:12:49.604296Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#model.load_weights(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:09:58.893861Z","iopub.execute_input":"2023-05-31T08:09:58.894285Z","iopub.status.idle":"2023-05-31T08:09:59.568622Z","shell.execute_reply.started":"2023-05-31T08:09:58.894252Z","shell.execute_reply":"2023-05-31T08:09:59.567412Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\nkeras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\ntflite_model = keras_model_converter.convert()\nwith open('/kaggle/working/model.tflite', 'wb') as f:\n    f.write(tflite_model)\n    \ninfargs = {\"selected_columns\" : SEL_COLS}\n\nwith open('inference_args.json', \"w\") as json_file:\n    json.dump(infargs, json_file)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:11:18.029424Z","iopub.execute_input":"2023-05-31T08:11:18.029885Z","iopub.status.idle":"2023-05-31T08:12:28.692918Z","shell.execute_reply.started":"2023-05-31T08:11:18.029850Z","shell.execute_reply":"2023-05-31T08:12:28.691851Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!zip submission.zip  './model.tflite' './inference_args.json'","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:12:32.744929Z","iopub.execute_input":"2023-05-31T08:12:32.745369Z","iopub.status.idle":"2023-05-31T08:12:35.149079Z","shell.execute_reply.started":"2023-05-31T08:12:32.745340Z","shell.execute_reply":"2023-05-31T08:12:35.147518Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"  adding: model.tflite (deflated 17%)\n  adding: inference_args.json (deflated 83%)\n","output_type":"stream"}]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(\"model.tflite\")\n\nREQUIRED_SIGNATURE = \"serving_default\"\nREQUIRED_OUTPUT = \"outputs\"\n\nwith open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    character_map = json.load(f)\nrev_character_map = {j:i for i,j in character_map.items()}\n\nfound_signatures = list(interpreter.get_signature_list().keys())\n\nif REQUIRED_SIGNATURE not in found_signatures:\n    raise KernelEvalException('Required input signature not found.')\n\nprediction_fn = interpreter.get_signature_runner(\"serving_default\")\noutput = prediction_fn(inputs=batch[0][0])\nprediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\nprint(prediction_str)","metadata":{"execution":{"iopub.status.busy":"2023-05-31T08:12:56.059267Z","iopub.execute_input":"2023-05-31T08:12:56.059670Z","iopub.status.idle":"2023-05-31T08:12:56.320320Z","shell.execute_reply.started":"2023-05-31T08:12:56.059642Z","shell.execute_reply":"2023-05-31T08:12:56.319041Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"rcreekhoushousele.com\n","output_type":"stream"}]}]}