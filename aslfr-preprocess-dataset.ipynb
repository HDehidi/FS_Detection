{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050f3f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:49:04.991440Z",
     "iopub.status.busy": "2023-05-28T08:49:04.990956Z",
     "iopub.status.idle": "2023-05-28T08:49:15.617794Z",
     "shell.execute_reply": "2023-05-28T08:49:15.616518Z"
    },
    "papermill": {
     "duration": 10.636043,
     "end_time": "2023-05-28T08:49:15.620639",
     "exception": false,
     "start_time": "2023-05-28T08:49:04.984596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7011fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:49:15.631014Z",
     "iopub.status.busy": "2023-05-28T08:49:15.629949Z",
     "iopub.status.idle": "2023-05-28T08:49:15.871056Z",
     "shell.execute_reply": "2023-05-28T08:49:15.869778Z"
    },
    "papermill": {
     "duration": 0.248352,
     "end_time": "2023-05-28T08:49:15.873822",
     "exception": false,
     "start_time": "2023-05-28T08:49:15.625470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816796431</td>\n",
       "      <td>217</td>\n",
       "      <td>3 creekhouse</td>\n",
       "      <td>b'3 creekhouse'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816825349</td>\n",
       "      <td>107</td>\n",
       "      <td>scales/kuhaylah</td>\n",
       "      <td>b'scales/kuhaylah'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816862427</td>\n",
       "      <td>0</td>\n",
       "      <td>hentaihubs.com</td>\n",
       "      <td>b'hentaihubs.com'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816909464</td>\n",
       "      <td>1</td>\n",
       "      <td>1383 william lanier</td>\n",
       "      <td>b'1383 william lanier'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816967051</td>\n",
       "      <td>63</td>\n",
       "      <td>988 franklin lane</td>\n",
       "      <td>b'988 franklin lane'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              path  file_id  sequence_id  participant_id  \\\n",
       "0  train_landmarks/5414471.parquet  5414471   1816796431             217   \n",
       "1  train_landmarks/5414471.parquet  5414471   1816825349             107   \n",
       "2  train_landmarks/5414471.parquet  5414471   1816862427               0   \n",
       "3  train_landmarks/5414471.parquet  5414471   1816909464               1   \n",
       "4  train_landmarks/5414471.parquet  5414471   1816967051              63   \n",
       "\n",
       "                phrase            phrase_bytes  \n",
       "0         3 creekhouse         b'3 creekhouse'  \n",
       "1      scales/kuhaylah      b'scales/kuhaylah'  \n",
       "2       hentaihubs.com       b'hentaihubs.com'  \n",
       "3  1383 william lanier  b'1383 william lanier'  \n",
       "4    988 franklin lane    b'988 franklin lane'  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inpdir = \"/kaggle/input/asl-fingerspelling\"\n",
    "df = pd.read_csv(f'{inpdir}/train.csv')\n",
    "df[\"phrase_bytes\"] = df[\"phrase\"].map(lambda x: x.encode(\"utf-8\"))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343c0020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:49:15.882110Z",
     "iopub.status.busy": "2023-05-28T08:49:15.881739Z",
     "iopub.status.idle": "2023-05-28T08:49:15.892165Z",
     "shell.execute_reply": "2023-05-28T08:49:15.891313Z"
    },
    "papermill": {
     "duration": 0.017328,
     "end_time": "2023-05-28T08:49:15.894441",
     "exception": false,
     "start_time": "2023-05-28T08:49:15.877113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "\n",
    "FACE = [f'x_face_{i}' for i in LIP] + [f'y_face_{i}' for i in LIP] + [f'z_face_{i}' for i in LIP]\n",
    "LHAND = [f'x_left_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)]\n",
    "RHAND = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
    "POSE = [f'x_pose_{i}' for i in range(33)] + [f'y_pose_{i}' for i in range(33)] + [f'z_pose_{i}' for i in range(33)]\n",
    "\n",
    "SEL_COLS = FACE + LHAND + RHAND + POSE\n",
    "FRAME_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a45e4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:49:15.902963Z",
     "iopub.status.busy": "2023-05-28T08:49:15.901994Z",
     "iopub.status.idle": "2023-05-28T09:41:17.785417Z",
     "shell.execute_reply": "2023-05-28T09:41:17.783957Z"
    },
    "papermill": {
     "duration": 3121.900221,
     "end_time": "2023-05-28T09:41:17.797954",
     "exception": false,
     "start_time": "2023-05-28T08:49:15.897733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [52:01<00:00, 45.91s/it]\n"
     ]
    }
   ],
   "source": [
    "def load_relevant_data_subset(pq_path):\n",
    "    return pd.read_parquet(pq_path, columns=SEL_COLS)\n",
    "\n",
    "for file_id in tqdm(df.file_id.unique()):\n",
    "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
    "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
    "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
    "    seq_refs = df.loc[df.file_id == file_id]\n",
    "    seqs = load_relevant_data_subset(pqfile)\n",
    "    \n",
    "    with tf.io.TFRecordWriter(tffile) as file_writer:\n",
    "        for seq_id, phrase in zip(seq_refs.sequence_id, seq_refs.phrase_bytes):\n",
    "            frames = seqs.iloc[seqs.index == seq_id]\n",
    "            frames128 = frames.fillna(-10).to_numpy()\n",
    "            frames128 = resize(frames128, (FRAME_LEN, len(SEL_COLS)))\n",
    "            frames = pd.DataFrame(data = frames128, columns=frames.columns)\n",
    "            \n",
    "            features = {COL: tf.train.Feature(float_list=tf.train.FloatList(value=frames[COL])) for COL in SEL_COLS}\n",
    "            features[\"phrase\"] = tf.train.Feature(bytes_list=tf.train.BytesList(value=[phrase]))\n",
    "            record_bytes = tf.train.Example(features=tf.train.Features(feature=features)).SerializeToString()\n",
    "            file_writer.write(record_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9810b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T09:41:17.820364Z",
     "iopub.status.busy": "2023-05-28T09:41:17.819969Z",
     "iopub.status.idle": "2023-05-28T09:41:19.249771Z",
     "shell.execute_reply": "2023-05-28T09:41:19.248177Z"
    },
    "papermill": {
     "duration": 1.444837,
     "end_time": "2023-05-28T09:41:19.252348",
     "exception": false,
     "start_time": "2023-05-28T09:41:17.807511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase\n",
      "phrase\n"
     ]
    }
   ],
   "source": [
    "def decode_fn(record_bytes):\n",
    "    schema = {COL: tf.io.FixedLenFeature([FRAME_LEN], dtype=tf.float32) for COL in SEL_COLS}\n",
    "    schema[\"phrase\"] = tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "    return tf.io.parse_single_example(record_bytes, schema)\n",
    "\n",
    "for file_id in df.file_id:\n",
    "    pqfile = f\"{inpdir}/train_landmarks/{file_id}.parquet\"\n",
    "    if not os.path.isdir(\"tfds\"): os.mkdir(\"tfds\")\n",
    "    tffile = f\"tfds/{file_id}.tfrecord\"\n",
    "    for batch in tf.data.TFRecordDataset([tffile]).map(decode_fn).take(2):\n",
    "        print(list(batch.keys())[0])\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3151.141726,
   "end_time": "2023-05-28T09:41:22.518109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-28T08:48:51.376383",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
